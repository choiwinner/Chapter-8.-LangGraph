{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f725852e-71ef-4615-8cac-011a516fbe72",
   "metadata": {},
   "source": [
    "# Agent Executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0860511-03c2-49bb-937b-035f84142b7e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd4ce41-4152-423b-b3f7-be3b4d568cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -U langgraph langchain langchain_openai langchainhub tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6398c4c1-da78-4595-8a5a-051ed2d1de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dace4a9-7c9e-4da2-bf7b-e58d0d05581e",
   "metadata": {},
   "source": [
    "## LangChain Agent 만들기\n",
    "\n",
    "먼저, LangChain 에이전트를 생성하겠습니다. LangChain 에이전트에 대한 자세한 정보는 [이 문서](https://python.langchain.com/v0.2/docs/concepts/#agents)를 참조하세요.\n",
    "\n",
    "- legacy agents: https://python.langchain.com/v0.1/docs/modules/agents/agent_types/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4499eb16-bca8-4a60-9a3a-2f34ae3f7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", streaming=True)\n",
    "\n",
    "# Construct the OpenAI Functions agent\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e58b3-fe3c-449d-b3c4-8fa2217afd07",
   "metadata": {},
   "source": [
    "## Graph State 정의하기\n",
    "\n",
    "이제 그래프 상태를 정의하겠습니다. 전통적인 LangChain 에이전트의 상태에는 몇 가지 속성이 있습니다:\n",
    "\n",
    "1. `input`: 이는 사용자로부터 전달된 주요 질문을 나타내는 입력 문자열입니다.\n",
    "2. `chat_history`: 이는 이전 대화 메시지로, 입력으로 전달됩니다.\n",
    "3. `intermediate_steps`: 이는 에이전트가 시간에 따라 수행한 액션과 이에 대한 관찰 목록입니다. 에이전트의 각 반복마다 업데이트됩니다.\n",
    "4. `agent_outcome`: 이는 에이전트의 응답으로, AgentAction 또는 AgentFinish가 될 수 있습니다. 에이전트가 AgentFinish일 경우, AgentExecutor는 작업을 완료해야 하며, 그렇지 않으면 요청된 도구를 호출해야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c941fb10-dbe5-4d6a-ab7d-133d01c33cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict, Union\n",
    "\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # The input string\n",
    "    input: str\n",
    "    # The list of previous messages in the conversation\n",
    "    chat_history: list[BaseMessage]\n",
    "    # The outcome of a given call to the agent\n",
    "    # Needs `None` as a valid type, since this is what this will start as\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    # List of actions and corresponding observations\n",
    "    # Here we annotate this with `operator.add` to indicate that operations to\n",
    "    # this state should be ADDED to the existing values (not overwrite it)\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27b281-cc9a-49c9-be78-8b98a7d905c4",
   "metadata": {},
   "source": [
    "## 노드 정의\n",
    "\n",
    "이제 그래프에서 몇 가지 다른 노드를 정의해야 합니다. `langgraph`에서 노드는 함수 또는 [Runnable](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)일 수 있습니다. 이를 위해 필요한 주요 노드는 다음과 같습니다:\n",
    "\n",
    "1. Agent: 어떤 액션을 취할지 결정하는 역할을 담당합니다.\n",
    "2. 도구를 호출하는 함수: 에이전트가 액션을 취하기로 결정한 경우, 이 노드가 해당 액션을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d61a970d-edf4-4eef-9678-28bab7c72331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor\n",
    "\n",
    "# This a helper class we have that is useful for running tools\n",
    "# It takes in an agent action and calls that tool and returns the result\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "\n",
    "# Define the agent\n",
    "def run_agent(state):\n",
    "    agent_outcome = agent_runnable.invoke(state)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "\n",
    "# Define the function to execute tools\n",
    "def execute_tools(state):\n",
    "    # Get the most recent agent_outcome - this is the key added in the `agent` above\n",
    "    agent_action = state[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "\n",
    "# Define logic that will be used to determine which conditional edge to go down\n",
    "def should_continue(state):\n",
    "    # If the agent outcome is an AgentFinish, then we return `exit` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    if isinstance(state[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    # Otherwise, an AgentAction is returned\n",
    "    # Here we return `continue` string\n",
    "    # This will be used when setting up the graph to define the flow\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b211f4-0c5c-4792-b18d-cd70907c71e7",
   "metadata": {},
   "source": [
    "## Graph 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4054dde-4618-49b7-998a-daa0c1d6d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214ae46e-c297-465d-86db-2b0312ed3530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': '미국 대선 날짜 2024'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': '미국 대선 날짜 2024'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"미국 대선 날짜 2024\"\\n}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9c1872f7-a99a-45de-8918-5d7fa5f0ae9c-0')])}\n",
      "----\n",
      "{'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': '미국 대선 날짜 2024'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': '미국 대선 날짜 2024'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"미국 대선 날짜 2024\"\\n}', 'name': 'tavily_search_results_json'}}, response_metadata={'finish_reason': 'function_call'}, id='run-9c1872f7-a99a-45de-8918-5d7fa5f0ae9c-0')]), \"[{'url': 'https://namu.wiki/w/2024년 미국 대통령 선거', 'content': '개요 [편집] 2024년 11월 5일 에 시행 예정인 미국 대통령 선거. 미국 의 60번째 대통령 선거이고 제47대 대통령 을 선출하거나 46대 대통령 조 바이든 이 재선 에 도전하는 선거다. 상대는 직전 45대 대통령 도널드 트럼프 로, 1912년 미국 대통령 선거 이후 112년만에 전 ...'}]\")]}\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': '2024년 미국 대통령 선거는 2024년 11월 5일에 시행될 예정입니다.'}, log='2024년 미국 대통령 선거는 2024년 11월 5일에 시행될 예정입니다.')}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"미국 대선 언제야? 검색해서 알려줘\", \"chat_history\": []}\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb662bc-de7d-4a57-a3e8-2f00dcf4ff8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
